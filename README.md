# Project

The goal of this project is to create a environment in local machine to explore the Spark combined with Delta Lake engine capabilities for free.

## Directories

The structure of the folders is:
* Delta Lake  - Path where the Delta Tables will be writen
* Notebooks   - Path where the Python Notebooks will be developed
* Power BI    - Small project in Power BI to explore the data in local Delta Tables
* Setup Files - All the files needed to setup the project

## Setup Files

- Download Apache Spark with Hadoop
    - https://spark.apache.org/downloads.html
        - Choose a Spark release: 3.5.0
        - Choose a package type:  "Pre-built for Apache Hadoop 3.3 and later"
        - If these options aren't appearing, go to the Spark Release Directory: https://archive.apache.org/dist/spark/

* Download and install Java Development Kit ( JDK )
**

* Download and install Anaconda project
** https://www.anaconda.com/download

## Dataset repositories

* Collection:  https://www.dataquest.io/blog/free-datasets-for-projects/
* Good option: https://www.kaggle.com/datasets